# -*- coding: utf-8 -*-
"""Proyek_Akhir_Membuat_Model_Sistem_Rekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kW838buyyFQNsXAOysoSJ0cuqkjvhmYm

# Herliana Nur Ekawati
# M07

# Data Understanding

Impor modul
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""Unduh dataset dari kaggle"""

!kaggle datasets download -d arashnic/book-recommendation-dataset

"""Unzip dataset"""

!unzip -qq /content/book-recommendation-dataset.zip

"""Baca data menggunakan fungsi pandas.read_csv"""

book = pd.read_csv('/content/Books.csv')
rating = pd.read_csv('/content/Ratings.csv')

"""# Univariate Exploratory Data Analysis

## Books
"""

book.info()

book = book.rename(columns={'Book-Title': 'book_title', 'Book-Author': 'book_author', 'Year-Of-Publication': 'book_year'})

print('Banyak buku: ', len(book.book_title.unique()))
print('Banyak penulis: ', len(book.book_author.unique()))
print('Judul Buku: ', book.book_title.unique())
print('Nama Penulis: ', book.book_author.unique())

"""## Ratings"""

rating.info()

rating = rating.rename(columns={'User-ID': 'userid', 'Book-Rating': 'book_rating'})

print('Angka rating: ', rating.book_rating.unique())
print('Banyak user: ', len(rating.userid.unique()))

"""# Data Preprocessing

Mengambil 5000 data books dan 1000 data ratings
"""

book = book[:5000]
rating = rating[:1000]

"""# Data preparation

## Mengatasi Missing Value

Mengecek apakah ada missing value atau tidak
"""

book.isnull().sum()

"""Drop seluruh kolom yang mengandung nilai Na/Null pada books"""

book = book.dropna()

"""Drop baris yang terdouble"""

book = book.drop_duplicates()

book

"""Konversi data series menjadi list"""

book_title = book['book_title'].tolist()
book_author = book['book_author'].tolist()
book_year = book['book_year'].tolist()
book_ISBN = book['ISBN'].tolist()

"""Membuat dictionary"""

new_book = pd.DataFrame({
    'book_title': book_title,
    'book_author': book_author,
    'book_year': book_year,
    'book_ISBN': book_ISBN
})
new_book.head()

"""# Model Development dengan Content Based Filtering

Mengecek data
"""

data = new_book
data.sample(5)

"""##TF-IDF Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer
tf = TfidfVectorizer()
tf.fit(data['book_author'])
tf.get_feature_names()

"""Lakukan fit dan transformasi ke dalam bentuk matriks"""

tfidf_matrix = tf.fit_transform(data['book_author'])
tfidf_matrix.shape

"""Menghasilkan vektor tf-idf dalam bentuk matriks"""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names(),
    index=data.book_title
).sample(20, axis=1, replace=True).sample(10, axis=0)

"""## Cosine Similarity

Menghitung derajat kesamaan
"""

from sklearn.metrics.pairwise import cosine_similarity
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Melihat matriks kesamaan"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['book_title'], columns=data['book_title'])
print('Shape:', cosine_sim_df.shape)
cosine_sim_df.sample(20, axis=1).sample(10, axis=0)

"""##Mendapatkan Rekomendasi"""

def author_recommend(i, S, items, k=5 ):
  idx = S.loc[:, i].to_numpy().argpartition(
      range(-1, -k, -1))
  closest = S.columns[idx[-1:-(k+2):-1]]
  closest = closest.drop(i, errors='ignore')
  return pd.DataFrame(closest).merge(items).head(k)

new_book

"""Menentukan rekomendasi buku yang mirip dengan Classical Mythology"""

item_book = 'Classical Mythology'
data[data.book_title.eq(item_book)]

"""Mendapatkan rekomendasi yang mirip"""

recommend = author_recommend(item_book, cosine_sim_df, new_book[['book_title', 'book_author']])
recommend

"""#Model Development dengan Collaborative Filtering

## Data Understanding

Impor library
"""

import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""##Data Preparation

Melakukan persiapan data untuk menyandikan (encode)
"""

user_ids = rating['userid'].unique().tolist()
 
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)
 
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

book_ids = rating['ISBN'].unique().tolist()
 
book_to_book_encoded = {x: i for i, x in enumerate(book_ids)}
print('encoded ISBN : ', book_to_book_encoded)
 
book_encoded_to_book = {i: x for i, x in enumerate(book_ids)}
print('encoded angka ke ISBN: ', book_encoded_to_book)

rating['user'] = rating['userid'].map(user_to_user_encoded)
rating['book'] = rating['ISBN'].map(book_to_book_encoded)

"""Mengecek jumlah data dan mengubah nilai rating menjadi float"""

num_users = len(user_encoded_to_user)
print(num_users)
num_book = len(book_encoded_to_book)
print(num_book)
rating['book_rating'] = rating['book_rating'].values.astype(np.float32)

min_rating = min(rating['book_rating'])
max_rating = max(rating['book_rating'])
 
print('Number of User: {}, Number of Book: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_book, min_rating, max_rating
))

"""## Membagi Data untuk Training dan Validasi

Acak data supaya distribusinya menjadi random
"""

rating = rating.sample(frac=1, random_state=42)
rating

"""Bagi data train dan validasi dengan komposisi 82:18."""

x = rating[['user', 'book']].values
 
y = rating['book_rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
train_indices = int(0.82 * rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""# Proses Training

Impor library
"""

from tensorflow import keras
from tensorflow.keras import layers
import tensorflow as tf

"""Membuat class RecommenderNet dengan keras Model class"""

class RecommenderNet(tf.keras.Model):
 
  def __init__(self, num_users, num_book, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_book = num_book
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.book_embedding = layers.Embedding( 
        num_book,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.book_bias = layers.Embedding(num_book, 1) 
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    book_vector = self.book_embedding(inputs[:, 1])
    book_bias = self.book_bias(inputs[:, 1]) 
 
    dot_user_book = tf.tensordot(user_vector, book_vector, 2) 
 
    x = dot_user_book + user_bias + book_bias
    
    return tf.nn.sigmoid(x)

"""Proses compile terhadap model"""

model = RecommenderNet(num_users, num_book, 50)
 
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Memulai training"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 5,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""## Visualisasi Metrik

Visualisasi proses training
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Mean Squared Error')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## Mendapatkan rekomendasi"""

book = new_book
rating = rating

userid = rating.userid.sample(1).iloc[0]
book_have_been_read_by_user = rating[rating.userid == userid]
 
book_have_not_been_read_by_user = book[book['book_ISBN'].isin(book_have_been_read_by_user.ISBN.values)]['book_ISBN'] 
book_have_not_been_read_by_user = list(
    set(book_have_not_been_read_by_user)
    .intersection(set(book_to_book_encoded.keys()))
)
 
book_have_not_been_read_by_user = [[book_to_book_encoded.get(x)] for x in book_have_not_been_read_by_user]
user_encoder = user_to_user_encoded.get(userid)
user_book_array = np.hstack(
    ([[user_encoder]] * len(book_have_not_been_read_by_user), book_have_not_been_read_by_user)
)

"""Memperoleh rekomendasi"""

rating = model.predict(user_book_array).flatten()
 
top_rating_indices = rating.argsort()[-10:][::-1]
recommended_book_ids = [
    book_encoded_to_book.get(book_have_not_been_read_by_user[x][0]) for x in top_rating_indices
]
 
top_book_user = (
    book_have_been_read_by_user.sort_values(
        by = 'book_rating',
        ascending=False
    )
    .head(5)
    .ISBN.values
)
 
book_rows = book[book['book_ISBN'].isin(top_book_user)]
for row in book_rows.itertuples():
    print(row.book_title, ':', row.book_author)
 
print('----' * 8)
print('Top 10 book recommendation')
print('----' * 8)
 
recommended_books = book[book['book_ISBN'].isin(recommended_book_ids)]
for row in recommended_books.itertuples():
    print(row.book_title, ':', row.book_author)

"""#Evaluation"""

books_that_have_been_read_row = book[book.book_title == item_book]
books_that_have_been_read_author = books_that_have_been_read_row.iloc[0]["book_author"]

book_recommendation_authors = recommend.book_author

real_author = 0
for i in range(5):
    if book_recommendation_authors[i] == books_that_have_been_read_author:
        real_author+=1

Accuracy = real_author/5*100
print("Accuracy of the model is {}%".format(Accuracy))